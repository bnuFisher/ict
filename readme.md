# 爬虫及文本分析实现

### 文档说明：

1.  爬虫代码在spider文件夹中。其中，news_spider.py是我写的一个很简单的单线程爬虫，可以直接用来爬取中国教育信息化网站上的新闻报道。网站地址：http://www.ict.edu.cn/

    该网站对爬虫十分友好，甚至不用伪装成浏览器即可访问，代理IP什么的就更不用了，是爬虫新手练习的好地方。不过，抓取量比较大的话，还是建议分批次抓取，设置好延迟时间，不要在短时间内猛爬，不然会给网站的服务器带去压力。
    
2.  爬取中国知网的论文信息前，需要先获得相关论文的url队列，知网搜索后，论文的链接在静态页面中是看不到的，同时知网对爬虫也不友好，很可能面临验证码输入(robot-check)甚至封锁IP的问题。我使用了专门的爬虫工具批量获取相关的论文链接，弹出验证码的检验框时，手工输入解决。
 
    详情可参考集搜客的相关教程 -- http://www.gooseeker.com/ <br>
   
    获取了url队列后，即可直接批量解析页面内容，爬取并保存需要的信息。由于硕士、博士学位论文和期刊论文的页面排版及需要抓取的内容略有差异，所以我写了三份代码。详情见：cnki_xxx.py。

3.  中文分词、关键词提取及词向量训练的示例代码在words_segmentation文件夹中，以对新闻文本的处理为例进行了说明，并附上了用到的自定义词典和停用词表。

4.  文本聚类和树状图绘制的代码可参考[《集体智慧编程》](https://book.douban.com/subject/3288908/)第三章的内容。我主要借鉴了书中的方法，实现上还需要制定一个关键词词频-论文标题的文本矩阵，这个并不难做到；不过要注意txt文件的中文编码问题，当时因为某个中文编码上的bug，我折腾了一整夜。

    另外，win7系统下，安装gensim module很可能会报错（反正我没成功），后来使用anaconda —— 一个用于科学计算的python发行版本 —— 解决了问题。

    最后，如果用Python3.X绘制树状图报错，可以改用Python2.7作为interpreter试试。

***
使用的IDE：PyCharm  ---- windows系统环境下学习Python的最佳集成开发工具之一，用edu后缀的邮箱申请，可以免费获得pro版本的使用权（一年一注册），业界良心，学生党福利。

最后的说明：上述代码我基本都修改完善过，但并没有再实现一遍，因此可能存在我没有察觉到的错误，欢迎批评指正。


***
写在一年后。

这个项目大约是一年前的现在完成的，算是一个命题作文。我曾将基于这个项目写成的论文投稿给若干个教育技术类的核心期刊，但都被拒搞了，理由基本都是研究结论没有新意，却没有人对结论提出方法论上的一针见血的评价。事实上，无监督学习的口碑一直不佳，在样本量非常有限的情况下，模型训练效果不好，研究结果也并不稳健。

那时我初学Python不到半年，对很多概念都一知半解，不知虚拟开发环境是何物，不确定是否应该深入学习爬虫，对未来的职业方向也缺乏清晰的规划，只是学习Python让我隐约感到了另一种职业可能性。现在回过头来看当初的代码，几乎不能直视。但我依然打算保留它们，就当是成长的见证。

2017年10月29日
